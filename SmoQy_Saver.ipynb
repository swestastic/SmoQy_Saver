{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b608914",
   "metadata": {},
   "source": [
    "# SmoQy_Saver\n",
    "\n",
    "Collect your outputs from SmoQyDQMC and do bin averaging across runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd400483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b526149",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mu_i, Mu_f, Mu_step = -10.0, 10.0, 0.1\n",
    "Beta_i, Beta_f, Beta_step = 1.0, 1.0, 1\n",
    "U_i, U_f, U_step = 5.0, 5.0, 0.1\n",
    "L_i, L_f, L_step = 6, 6, 1\n",
    "sID_i, sID_f, sID_step = 1, 12, 1\n",
    "\n",
    "Mus = np.arange(Mu_i, Mu_f+Mu_step, Mu_step).round(2)\n",
    "Betas = np.arange(Beta_i, Beta_f+Beta_step, Beta_step).round(2)\n",
    "Us = np.arange(U_i, U_f+U_step, U_step).round(2)\n",
    "Ls = np.arange(L_i, L_f+L_step, L_step,dtype=int).round(2)\n",
    "sIDs = np.arange(sID_i, sID_f+sID_step, sID_step).round(2)\n",
    "\n",
    "sID = sIDs[0]\n",
    "U = Us[0]\n",
    "L = Ls[0]\n",
    "mu = Mus[0]\n",
    "beta = Betas[0]\n",
    "\n",
    "N_bins = 3\n",
    "Nperbin = len(sIDs) // N_bins\n",
    "if len(sIDs) % N_bins != 0:\n",
    "    raise ValueError(\"Number of sIDs is not divisible by N_bins\")\n",
    "\n",
    "lattice = 'kagome'\n",
    "spaces = ['position', 'momentum']\n",
    "time_displaced = False\n",
    "integrated = False\n",
    "LessIO = True # Use for LessIO SmoQy fork  \n",
    "filepath = r\"data\" # Path to data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "070aa847",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lattice == 'square':\n",
    "    N_bonds = 2\n",
    "    N_orbitals = 1\n",
    "elif lattice == 'kagome':\n",
    "    N_bonds = 6\n",
    "    N_orbitals = 3\n",
    "else:\n",
    "    raise ValueError(f\"Unknown lattice type: {lattice}, manually define N_bonds and N_orbitals\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39387fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bins(data,Nperbin,Nbins):\n",
    "    # Each bin is a point in the array, values are continuously added to it\n",
    "    # Ex. 'Energy_bins' would be a 1xNbins array containing values of E (each value is a sum of Nperbin values)\n",
    "    # This function takes the average of each bin\n",
    "    \n",
    "    # Nbins = len(data), but we can also supply it as an argument\n",
    "\n",
    "    if Nbins != len(data):\n",
    "        print('Check array size')\n",
    "        return \n",
    "        \n",
    "    if Nbins == 1 and Nperbin == 1:\n",
    "        Bin_totalavg = data[0]\n",
    "        ErrorBars = np.zeros_like(Bin_totalavg)\n",
    "        return Bin_totalavg,ErrorBars\n",
    "\n",
    "    # data = data.reshape(Nbins,Nperbin) # Reshape the data into a 2D array, where each row is a bin\n",
    "\n",
    "    Bin_avgs = data / Nperbin # Not sure if this is correct but it seems roughly right? Don't really see where the math justification is though\n",
    "    # You would think it should be Nperbin \n",
    "\n",
    "    Bin_totalavg=np.mean(Bin_avgs) #calculates one total value\n",
    "\n",
    "    #This is where we calculate the error bars\n",
    "    ErrorBars=0\n",
    "    for i in range(Nbins):\n",
    "        ErrorBars+=(Bin_avgs[i]-Bin_totalavg)**2\n",
    "    ErrorBars=np.sqrt(1/Nbins)*np.sqrt(1/(Nbins-1))*np.sqrt(ErrorBars)\n",
    "\n",
    "    return Bin_totalavg,ErrorBars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd7a368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(sID, U, mu, beta, L, filepath = f\"data\", lattice = \"kagome\", LessIO = False):\n",
    "    '''\n",
    "    Based on the naming parameters we supply sID, U, mu, and beta, lookup the folder name that the data from SmoQY is saved in.\n",
    "\n",
    "    Paramters:\n",
    "    sID (int): Simulation ID number\n",
    "    U (float): Interaction Energy\n",
    "    mu (float): Chemical Potential\n",
    "    beta (float): Inverse Temperature \n",
    "    L (int): Number of times the unit cell is propogated along the unit vectors, for a 1D chain this is the number of sites\n",
    "    filepath (string): Path to the parent folder where the data is stored\n",
    "    \n",
    "    Returns:\n",
    "    global_stats (pd.dataframe): Global system statistics like density, action, compressibility, and double occupancy\n",
    "    local_stats (pd.dataframe): Local statistics for each orbital like onsite energy, density, and double occupancy\n",
    "    spin_z_corr (pd.dataframe): Spin z correlation statistics for equal-time measurements\n",
    "    spin_x_corr (pd.dataframe): Spin x correlation statistics for equal-time measurements\n",
    "    '''\n",
    "    folder_name = f\"hubbard_{lattice}_U{U:.2f}_mu{mu:.2f}_L{L}_b{beta:.2f}-{sID}\"\n",
    "\n",
    "    if LessIO:\n",
    "        global_stats = pd.read_csv(f\"{filepath}/{folder_name}/global_stats.csv\", sep='\\s+')\n",
    "        local_stats = pd.read_csv(f\"{filepath}/{folder_name}/local_stats.csv\", sep='\\s+')\n",
    "        spin_z_corr = pd.read_csv(f\"{filepath}/{folder_name}/spin_z_position_equal-time_stats.csv\", sep='\\s+')\n",
    "        spin_x_corr = pd.read_csv(f\"{filepath}/{folder_name}/spin_x_position_equal-time_stats.csv\", sep='\\s+')\n",
    "    else:\n",
    "        global_stats = pd.read_csv(f\"{filepath}/{folder_name}/global_stats.csv\", sep='\\s+')\n",
    "        local_stats = pd.read_csv(f\"{filepath}/{folder_name}/local_stats.csv\", sep='\\s+')\n",
    "        spin_z_corr = pd.read_csv(f\"{filepath}/{folder_name}/equal-time/spin_z/spin_z_position_equal-time_stats.csv\", sep='\\s+')\n",
    "        spin_x_corr = pd.read_csv(f\"{filepath}/{folder_name}/equal-time/spin_x/spin_x_position_equal-time_stats.csv\", sep='\\s+')\n",
    "    \n",
    "    return global_stats, local_stats, spin_z_corr, spin_x_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa2ab8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_data(stats, observable, data):\n",
    "    '''\n",
    "    Grabs the data for a given observable from the stats dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    stats (pd.dataframe): Dataframe containing the statistics\n",
    "    observable (str): Name of the observable to grab data for\n",
    "    \n",
    "    Returns:\n",
    "    data (np.array): Array containing the data for the observable\n",
    "    '''\n",
    "    row = stats[stats[\"MEASUREMENT\"] == observable]\n",
    "    if not row.empty:\n",
    "        values = row['MEAN_R'].values\n",
    "        if len(values) == 1:\n",
    "            return values[0]\n",
    "        else:\n",
    "            # check that the values are of the expected length\n",
    "            if len(data[observable][0]) == len(values):\n",
    "                return values\n",
    "            else:\n",
    "                print(f\"Length mismatch for observable '{observable}': expected {len(data[observable])}, got {len(values)}\")\n",
    "                return None\n",
    "    else:\n",
    "        print(f\"Observable '{observable}' not found in stats.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "967e29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_neighbors(spin_z_corr, spin_x_corr, lattice, correlation):\n",
    "\n",
    "    if correlation == 'spin-z-position_equal-time':\n",
    "        dataframe = spin_z_corr\n",
    "    elif correlation == 'spin-x-position_equal-time':\n",
    "        dataframe = spin_x_corr\n",
    "\n",
    "    if lattice == 'square':\n",
    "        nearest_neighbors = np.array((\n",
    "            dataframe.loc[(dataframe['R_1'] == 0) & (dataframe['R_2'] == 1), 'MEAN_R'].values,\n",
    "            dataframe.loc[(dataframe['R_2'] == 0) & (dataframe['R_1'] == 1), 'MEAN_R'].values\n",
    "        ))\n",
    "\n",
    "    elif lattice == 'kagome':\n",
    "\n",
    "        within_unit_cell = np.array(((1,2,0,0),\n",
    "                                    (1,3,0,0),\n",
    "                                    (2,3,0,0)))\n",
    "\n",
    "        nearest_neighbors = []\n",
    "        \n",
    "        ######## within unit cell ########\n",
    "        for i in range(len(within_unit_cell)):\n",
    "            nearest_neighbors.append(dataframe.loc[\n",
    "                (dataframe['ORBITAL_ID_1'] == within_unit_cell[i][0]) &\n",
    "                (dataframe['ORBITAL_ID_2'] == within_unit_cell[i][1]) &\n",
    "                (dataframe['R_1'] == within_unit_cell[i][2]) &\n",
    "                (dataframe['R_2'] == within_unit_cell[i][3]),\n",
    "                'MEAN_R'\n",
    "            ].values)\n",
    "\n",
    "    return nearest_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcfe598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data structures\n",
    "data = {}\n",
    "results = {}\n",
    "\n",
    "global_observables = ['sgn', 'sgndetGup', 'sgndetGdn', 'density', 'density_up', 'density_dn', 'double_occ', 'Nsqrd', 'chemical_potential', 'compressibility']\n",
    "local_observables = ['hubbard_energy', 'hopping_energy', 'onsite_energy']\n",
    "if LessIO:\n",
    "    global_observables += ['total_energy', 'total_energy_sqrd']\n",
    "\n",
    "for observable in global_observables:\n",
    "    data[observable] = np.zeros((len(Mus), N_bins))\n",
    "for observable in local_observables:\n",
    "    if observable in ['hubbard_energy', 'onsite_energy']:\n",
    "        data[observable] = np.zeros((len(Mus), N_orbitals, N_bins))\n",
    "    elif observable == 'hopping_energy':\n",
    "        data[observable] = np.zeros((len(Mus), N_bonds, N_bins))\n",
    "\n",
    "correlations = ['spin-z-position_equal-time', 'spin-x-position_equal-time', 'structure_factor']\n",
    "corr_bins = {corr: np.zeros((len(Mus), N_bins)) for corr in correlations}\n",
    "\n",
    "# Combined loop\n",
    "for mu_index, mu in enumerate(Mus):\n",
    "    mu_val = 0.0 if -0.05 < mu < 0.05 else mu\n",
    "    for sID_index, sID in enumerate(sIDs):\n",
    "        try:\n",
    "            global_stats, local_stats, spin_z_corr, spin_x_corr = get_stats(sID, U, mu_val, beta, L, lattice=lattice, LessIO=LessIO, filepath=filepath)\n",
    "            # Global observables\n",
    "            for observable in global_observables:\n",
    "                data[observable][mu_index][sID_index % N_bins] += grab_data(global_stats, observable, data)\n",
    "            # Local observables\n",
    "            for observable in local_observables:\n",
    "                if len(data[observable][0]) == N_orbitals:\n",
    "                    if N_orbitals == 1:\n",
    "                        data[observable][mu_index][0][sID_index % N_bins] += grab_data(local_stats, observable, data)\n",
    "                    else:\n",
    "                        for orbital_index in range(N_orbitals):\n",
    "                            data[observable][mu_index][orbital_index][sID_index % N_bins] += grab_data(local_stats, observable, data)[orbital_index]\n",
    "                elif len(data[observable][0]) == N_bonds:\n",
    "                    for bond_index in range(N_bonds):\n",
    "                        data[observable][mu_index][bond_index][sID_index % N_bins] += grab_data(local_stats, observable, data)[bond_index]\n",
    "            # Correlations\n",
    "            for correlation in correlations:\n",
    "                if correlation == \"structure_factor\":\n",
    "                    total_value = np.sum((spin_z_corr['MEAN_R'].values + 2*spin_x_corr['MEAN_R'].values)/3)\n",
    "                    corr_bins[correlation][mu_index][sID_index % N_bins] += total_value\n",
    "                else:\n",
    "                    nearest_neighbors = find_nearest_neighbors(spin_z_corr, spin_x_corr, lattice, correlation)\n",
    "                    nearest_value = np.mean(nearest_neighbors)\n",
    "                    corr_bins[correlation][mu_index][sID_index % N_bins] += nearest_value\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving data for sID: {sID}, U: {U}, mu: {mu_val}, beta: {beta}, L: {L}. Skipping this configuration.\")\n",
    "\n",
    "# Bin and store results\n",
    "for observable in global_observables:\n",
    "    results[observable] = np.zeros((2, len(Mus)))\n",
    "    for i in range(len(Mus)):\n",
    "        results[observable][0][i], results[observable][1][i] = bins(data[observable][i], Nperbin, N_bins)\n",
    "\n",
    "for observable in local_observables:\n",
    "    if len(data[observable][0]) == N_orbitals:\n",
    "        results[observable] = np.zeros((N_orbitals, 2, len(Mus)))\n",
    "        for orbital_index in range(N_orbitals):\n",
    "            for i in range(len(Mus)):\n",
    "                results[observable][orbital_index][0][i], results[observable][orbital_index][1][i] = bins(data[observable][i][orbital_index], Nperbin, N_bins)\n",
    "    elif len(data[observable][0]) == N_bonds:\n",
    "        results[observable] = np.zeros((N_bonds, 2, len(Mus)))\n",
    "        for bond_index in range(N_bonds):\n",
    "            for i in range(len(Mus)):\n",
    "                results[observable][bond_index][0][i], results[observable][bond_index][1][i] = bins(data[observable][i][bond_index], Nperbin, N_bins)\n",
    "\n",
    "for correlation in correlations:\n",
    "    results[correlation] = np.zeros((2, len(Mus)))\n",
    "    for i in range(len(Mus)):\n",
    "        results[correlation][0][i], results[correlation][1][i] = bins(corr_bins[correlation][i], Nperbin, N_bins)\n",
    "\n",
    "results['spin-xyz-position_equal-time'] = np.zeros((2, len(Mus)))\n",
    "results['spin-xyz-position_equal-time'][0] = 1/3 * results['spin-z-position_equal-time'][0] + 2/3 * results['spin-x-position_equal-time'][0]\n",
    "results['spin-xyz-position_equal-time'][1] = np.sqrt(\n",
    "    (1/3 * results['spin-z-position_equal-time'][1])**2 +\n",
    "    (2/3 * results['spin-x-position_equal-time'][1])**2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7a1d33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dont_write = ['spin-z-position_equal-time', 'spin-x-position_equal-time', 'hubbard_energy', 'hopping_energy', 'onsite_energy']\n",
    "\n",
    "# Average and error for hubbard_energy\n",
    "results['hubbard_energy_avg'] = np.zeros((2, len(Mus)))\n",
    "for i in range(len(Mus)):\n",
    "    results['hubbard_energy_avg'][0][i] = np.sum(results['hubbard_energy'][:, 0, i])\n",
    "    results['hubbard_energy_avg'][1][i] = np.sqrt(np.sum(results['hubbard_energy'][:, 1, i] ** 2))\n",
    "\n",
    "# Average and error for hopping_energy\n",
    "results['hopping_energy_avg'] = np.zeros((2, len(Mus)))\n",
    "for i in range(len(Mus)):\n",
    "    results['hopping_energy_avg'][0][i] = np.sum(results['hopping_energy'][:, 0, i])\n",
    "    results['hopping_energy_avg'][1][i] = np.sqrt(np.sum(results['hopping_energy'][:, 1, i] ** 2))\n",
    "\n",
    "# Average and error for onsite_energy\n",
    "results['onsite_energy_avg'] = np.zeros((2, len(Mus)))\n",
    "for i in range(len(Mus)):\n",
    "    results['onsite_energy_avg'][0][i] = np.sum(results['onsite_energy'][:, 0, i])\n",
    "    results['onsite_energy_avg'][1][i] = np.sqrt(np.sum(results['onsite_energy'][:, 1, i] ** 2))\n",
    "\n",
    "filename = 'SmoQy_Results.csv'\n",
    "header = ['observable', 'mu', 'value', 'error', 'beta', 'L', 'U', 'num_runs', 'lattice']\n",
    "num_runs = sIDs[-1] - sIDs[0] + 1\n",
    "\n",
    "existing_entries = set()\n",
    "if os.path.exists(filename):\n",
    "    with open(filename, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            key = (row['mu'], row['beta'], row['L'], row['U'], row['lattice'])\n",
    "            existing_entries.add(key)\n",
    "\n",
    "with open(filename, 'a', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # Write header only if file is new/empty\n",
    "    if os.stat(filename).st_size == 0:\n",
    "        writer.writerow(header)\n",
    "    for key in results:\n",
    "        if key in dont_write:\n",
    "            continue\n",
    "        if isinstance(results[key], np.ndarray) and results[key].ndim == 2 and results[key].shape[1] == len(Mus):\n",
    "            for i, mu in enumerate(Mus):\n",
    "                entry_key = (str(mu), str(beta), str(L), str(U), lattice)\n",
    "                if entry_key not in existing_entries:\n",
    "                    writer.writerow([key, mu, results[key][0][i], results[key][1][i], beta, L, U, num_runs, lattice])\n",
    "        elif isinstance(results[key], np.ndarray) and results[key].ndim == 3 and results[key].shape[2] == len(Mus):\n",
    "            for idx in range(results[key].shape[0]):\n",
    "                for i, mu in enumerate(Mus):\n",
    "                    entry_key = (str(mu), str(beta), str(L), str(U), lattice)\n",
    "                    if entry_key not in existing_entries:\n",
    "                        writer.writerow([f\"{key}_{idx}\", mu, results[key][idx][0][i], results[key][idx][1][i], beta, L, U, num_runs, lattice])\n",
    "        else:\n",
    "            print(f\"Skipping key '{key}' with unexpected shape: {np.shape(results[key])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
